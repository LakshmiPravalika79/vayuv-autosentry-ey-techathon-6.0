{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2119f65",
   "metadata": {},
   "source": [
    "# AutoSentry AI - Predictive Vehicle Maintenance Model Training\n",
    "\n",
    "**Team:** EverLearners  \n",
    "**Project:** EY Techathon 6.0 - Autonomous Predictive Vehicle Maintenance System\n",
    "\n",
    "This notebook trains machine learning models to predict vehicle maintenance failures using synthetic telematics data and historical maintenance records.\n",
    "\n",
    "## Objectives:\n",
    "1. Load and preprocess vehicle telemetry data\n",
    "2. Engineer predictive features from sensor readings\n",
    "3. Train RandomForest and XGBoost classifiers\n",
    "4. Evaluate model performance and select best model\n",
    "5. Save model artifacts for production deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b55b05",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_absolute_error, mean_squared_error\n",
    ")\n",
    "\n",
    "# XGBoost (optional - install with: pip install xgboost)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not installed. Using GradientBoosting as alternative.\")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"XGBoost available: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa764a",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Synthetic Vehicle Data\n",
    "\n",
    "We load telemetry data from our 10 synthetic vehicles. Each vehicle has sensor readings including:\n",
    "- Engine temperature (Â°C)\n",
    "- Oil pressure (PSI)\n",
    "- Battery voltage (V)\n",
    "- Tire pressure (PSI)\n",
    "- Brake pad wear (%)\n",
    "- Coolant level (%)\n",
    "- Transmission temperature (Â°C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "DATA_DIR = \"../../data\"\n",
    "TRAINING_DATA_PATH = os.path.join(DATA_DIR, \"training_data.csv\")\n",
    "TELEMETRY_PATH = os.path.join(DATA_DIR, \"vehicle_telemetry.json\")\n",
    "MAINTENANCE_PATH = os.path.join(DATA_DIR, \"maintenance_records.json\")\n",
    "\n",
    "# Load training data\n",
    "if os.path.exists(TRAINING_DATA_PATH):\n",
    "    df = pd.read_csv(TRAINING_DATA_PATH)\n",
    "    print(f\"Loaded training data: {df.shape[0]} samples, {df.shape[1]} features\")\n",
    "else:\n",
    "    # Generate synthetic data if not available\n",
    "    print(\"Generating synthetic training data...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'vehicle_id': np.random.choice([f'VH{i:03d}' for i in range(1, 11)], n_samples),\n",
    "        'timestamp': pd.date_range('2025-01-01', periods=n_samples, freq='6H'),\n",
    "        'engine_temp': np.random.normal(95, 15, n_samples),\n",
    "        'oil_pressure': np.random.normal(40, 8, n_samples),\n",
    "        'battery_voltage': np.random.normal(12.3, 0.8, n_samples),\n",
    "        'fuel_level': np.random.uniform(10, 100, n_samples),\n",
    "        'tire_pressure_avg': np.random.normal(31, 2, n_samples),\n",
    "        'brake_pad_wear_avg': np.random.uniform(0.1, 0.9, n_samples),\n",
    "        'odometer': np.random.uniform(10000, 180000, n_samples),\n",
    "        'speed': np.random.uniform(0, 80, n_samples),\n",
    "        'rpm': np.random.normal(2500, 500, n_samples),\n",
    "        'coolant_level': np.random.uniform(0.4, 1.0, n_samples),\n",
    "        'transmission_temp': np.random.normal(90, 20, n_samples),\n",
    "        'check_engine_light': np.random.choice([0, 1], n_samples, p=[0.85, 0.15])\n",
    "    })\n",
    "    \n",
    "    # Create target variable based on conditions\n",
    "    df['failure_within_30_days'] = 0\n",
    "    df.loc[df['engine_temp'] > 110, 'failure_within_30_days'] = 1\n",
    "    df.loc[df['oil_pressure'] < 28, 'failure_within_30_days'] = 1\n",
    "    df.loc[df['battery_voltage'] < 11, 'failure_within_30_days'] = 1\n",
    "    df.loc[df['brake_pad_wear_avg'] < 0.15, 'failure_within_30_days'] = 1\n",
    "    df.loc[df['coolant_level'] < 0.5, 'failure_within_30_days'] = 1\n",
    "    df.loc[df['transmission_temp'] > 120, 'failure_within_30_days'] = 1\n",
    "    \n",
    "    # Create failure type\n",
    "    df['failure_type'] = 'none'\n",
    "    df.loc[df['engine_temp'] > 110, 'failure_type'] = 'cooling_system'\n",
    "    df.loc[df['oil_pressure'] < 28, 'failure_type'] = 'engine'\n",
    "    df.loc[df['battery_voltage'] < 11, 'failure_type'] = 'electrical'\n",
    "    df.loc[df['brake_pad_wear_avg'] < 0.15, 'failure_type'] = 'brakes'\n",
    "    df.loc[(df['coolant_level'] < 0.5) | (df['transmission_temp'] > 120), 'failure_type'] = 'multiple'\n",
    "\n",
    "# Display data info\n",
    "print(\"\\nDataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07412587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b61104",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering\n",
    "\n",
    "Create additional features from raw sensor data:\n",
    "- Health scores for each system\n",
    "- Rolling averages for trend detection\n",
    "- Rate of change features\n",
    "- Normalized mileage features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create derived features for better prediction\"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # Engine health score (normalized, 1 = optimal, 0 = critical)\n",
    "    df_fe['engine_health'] = 1.0 - np.clip((df_fe['engine_temp'] - 90) / 40, 0, 1)\n",
    "    \n",
    "    # Oil health score\n",
    "    df_fe['oil_health'] = np.clip(df_fe['oil_pressure'] / 45, 0, 1)\n",
    "    \n",
    "    # Battery health score\n",
    "    df_fe['battery_health'] = np.clip((df_fe['battery_voltage'] - 10) / 3, 0, 1)\n",
    "    \n",
    "    # Cooling system health\n",
    "    df_fe['cooling_health'] = np.clip(df_fe['coolant_level'], 0, 1)\n",
    "    \n",
    "    # Transmission health\n",
    "    df_fe['trans_health'] = 1.0 - np.clip((df_fe['transmission_temp'] - 80) / 50, 0, 1)\n",
    "    \n",
    "    # Overall health score (weighted average)\n",
    "    df_fe['overall_health'] = (\n",
    "        0.25 * df_fe['engine_health'] +\n",
    "        0.20 * df_fe['oil_health'] +\n",
    "        0.15 * df_fe['battery_health'] +\n",
    "        0.20 * df_fe['cooling_health'] +\n",
    "        0.20 * df_fe['trans_health']\n",
    "    )\n",
    "    \n",
    "    # Mileage tier (normalized)\n",
    "    df_fe['mileage_normalized'] = df_fe['odometer'] / 200000\n",
    "    \n",
    "    # High mileage flag\n",
    "    df_fe['high_mileage'] = (df_fe['odometer'] > 100000).astype(int)\n",
    "    \n",
    "    # Critical indicators\n",
    "    df_fe['critical_temp'] = (df_fe['engine_temp'] > 105).astype(int)\n",
    "    df_fe['low_oil'] = (df_fe['oil_pressure'] < 30).astype(int)\n",
    "    df_fe['low_battery'] = (df_fe['battery_voltage'] < 11.5).astype(int)\n",
    "    df_fe['low_brakes'] = (df_fe['brake_pad_wear_avg'] < 0.2).astype(int)\n",
    "    \n",
    "    # Risk score (sum of critical indicators)\n",
    "    df_fe['risk_score'] = (\n",
    "        df_fe['critical_temp'] + \n",
    "        df_fe['low_oil'] + \n",
    "        df_fe['low_battery'] + \n",
    "        df_fe['low_brakes'] +\n",
    "        df_fe['check_engine_light']\n",
    "    )\n",
    "    \n",
    "    return df_fe\n",
    "\n",
    "# Apply feature engineering\n",
    "df_processed = engineer_features(df)\n",
    "print(f\"Features after engineering: {df_processed.shape[1]}\")\n",
    "print(\"\\nNew features created:\")\n",
    "new_features = ['engine_health', 'oil_health', 'battery_health', 'cooling_health', \n",
    "                'trans_health', 'overall_health', 'mileage_normalized', 'high_mileage',\n",
    "                'critical_temp', 'low_oil', 'low_battery', 'low_brakes', 'risk_score']\n",
    "df_processed[new_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a28203",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Class distribution\n",
    "failure_counts = df_processed['failure_within_30_days'].value_counts()\n",
    "axes[0].bar(['No Failure', 'Failure'], failure_counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Target Variable Distribution', fontsize=14)\n",
    "axes[0].set_ylabel('Count')\n",
    "for i, v in enumerate(failure_counts.values):\n",
    "    axes[0].text(i, v + 10, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Failure rate by vehicle\n",
    "if 'vehicle_id' in df_processed.columns:\n",
    "    vehicle_failure_rate = df_processed.groupby('vehicle_id')['failure_within_30_days'].mean().sort_values(ascending=False)\n",
    "    axes[1].barh(vehicle_failure_rate.index, vehicle_failure_rate.values, color='#3498db')\n",
    "    axes[1].set_xlabel('Failure Rate')\n",
    "    axes[1].set_title('Failure Rate by Vehicle', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClass Distribution:\")\n",
    "print(f\"  No Failure: {failure_counts.get(0, 0)} ({failure_counts.get(0, 0)/len(df_processed)*100:.1f}%)\")\n",
    "print(f\"  Failure: {failure_counts.get(1, 0)} ({failure_counts.get(1, 0)/len(df_processed)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor distributions\n",
    "sensor_cols = ['engine_temp', 'oil_pressure', 'battery_voltage', 'coolant_level', \n",
    "               'transmission_temp', 'brake_pad_wear_avg']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(sensor_cols):\n",
    "    if col in df_processed.columns:\n",
    "        # Plot distribution for failure vs no failure\n",
    "        df_processed[df_processed['failure_within_30_days']==0][col].hist(\n",
    "            ax=axes[i], bins=30, alpha=0.6, label='No Failure', color='#2ecc71'\n",
    "        )\n",
    "        df_processed[df_processed['failure_within_30_days']==1][col].hist(\n",
    "            ax=axes[i], bins=30, alpha=0.6, label='Failure', color='#e74c3c'\n",
    "        )\n",
    "        axes[i].set_title(f'{col.replace(\"_\", \" \").title()}', fontsize=12)\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.suptitle('Sensor Distributions by Failure Status', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "numeric_cols = ['engine_temp', 'oil_pressure', 'battery_voltage', 'coolant_level',\n",
    "                'transmission_temp', 'brake_pad_wear_avg', 'odometer', 'rpm',\n",
    "                'engine_health', 'oil_health', 'battery_health', 'overall_health',\n",
    "                'risk_score', 'failure_within_30_days']\n",
    "\n",
    "# Filter to only existing columns\n",
    "numeric_cols = [col for col in numeric_cols if col in df_processed.columns]\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr_matrix = df_processed[numeric_cols].corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdYlBu_r',\n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with target\n",
    "if 'failure_within_30_days' in corr_matrix.columns:\n",
    "    target_corr = corr_matrix['failure_within_30_days'].drop('failure_within_30_days').sort_values(key=abs, ascending=False)\n",
    "    print(\"Top correlations with failure:\")\n",
    "    print(target_corr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11f40f",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e512d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for training\n",
    "feature_columns = [\n",
    "    'engine_temp', 'oil_pressure', 'battery_voltage', 'fuel_level',\n",
    "    'tire_pressure_avg', 'brake_pad_wear_avg', 'odometer', 'speed',\n",
    "    'rpm', 'coolant_level', 'transmission_temp', 'check_engine_light',\n",
    "    'engine_health', 'oil_health', 'battery_health', 'cooling_health',\n",
    "    'trans_health', 'overall_health', 'mileage_normalized', 'high_mileage',\n",
    "    'risk_score'\n",
    "]\n",
    "\n",
    "# Filter to only existing columns\n",
    "feature_columns = [col for col in feature_columns if col in df_processed.columns]\n",
    "\n",
    "print(f\"Features selected: {len(feature_columns)}\")\n",
    "print(feature_columns)\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_processed[feature_columns].values\n",
    "y = df_processed['failure_within_30_days'].values\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(f\"  No Failure: {sum(y_train==0)} ({sum(y_train==0)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Failure: {sum(y_train==1)} ({sum(y_train==1)/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled using StandardScaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe1cd3",
   "metadata": {},
   "source": [
    "## 6. Train RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdfdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForest with hyperparameter tuning\n",
    "print(\"Training RandomForest Classifier...\")\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf_model, param_grid_rf, cv=5, scoring='f1',\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(f\"\\nBest RandomForest Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best CV F1 Score: {grid_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d5671a",
   "metadata": {},
   "source": [
    "## 7. Train XGBoost/GradientBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost or GradientBoosting\n",
    "print(\"Training Gradient Boosting Classifier...\")\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    # Calculate scale_pos_weight for imbalanced data\n",
    "    scale_pos_weight = sum(y_train == 0) / sum(y_train == 1) if sum(y_train == 1) > 0 else 1\n",
    "    \n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        xgb_model, param_grid_xgb, cv=5, scoring='f1',\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "else:\n",
    "    # Use GradientBoosting as alternative\n",
    "    param_grid_gb = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "    }\n",
    "    \n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "    \n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        gb_model, param_grid_gb, cv=5, scoring='f1',\n",
    "        n_jobs=-1, verbose=1\n",
    "    )\n",
    "\n",
    "grid_search_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "print(f\"\\nBest Boosting Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Best CV F1 Score: {grid_search_xgb.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4474866",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cf140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model and return metrics\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba) if len(np.unique(y_test)) > 1 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"  ROC-AUC:   {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    return metrics, y_pred, y_proba\n",
    "\n",
    "# Evaluate both models\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL EVALUATION ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf_metrics, rf_pred, rf_proba = evaluate_model(best_rf, X_test_scaled, y_test, \"RandomForest\")\n",
    "xgb_metrics, xgb_pred, xgb_proba = evaluate_model(best_xgb, X_test_scaled, y_test, \"GradientBoosting/XGBoost\")\n",
    "\n",
    "# Select best model\n",
    "if rf_metrics['f1'] >= xgb_metrics['f1']:\n",
    "    best_model = best_rf\n",
    "    best_model_name = \"RandomForest\"\n",
    "    best_metrics = rf_metrics\n",
    "else:\n",
    "    best_model = best_xgb\n",
    "    best_model_name = \"GradientBoosting/XGBoost\"\n",
    "    best_metrics = xgb_metrics\n",
    "\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name} (F1: {best_metrics['f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices and ROC curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# RandomForest Confusion Matrix\n",
    "cm_rf = confusion_matrix(y_test, rf_pred)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('RandomForest Confusion Matrix')\n",
    "axes[0, 0].set_xlabel('Predicted')\n",
    "axes[0, 0].set_ylabel('Actual')\n",
    "\n",
    "# GradientBoosting Confusion Matrix\n",
    "cm_xgb = confusion_matrix(y_test, xgb_pred)\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Greens', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('GradientBoosting Confusion Matrix')\n",
    "axes[0, 1].set_xlabel('Predicted')\n",
    "axes[0, 1].set_ylabel('Actual')\n",
    "\n",
    "# ROC Curves\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_proba)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_proba)\n",
    "\n",
    "axes[1, 0].plot(fpr_rf, tpr_rf, label=f'RandomForest (AUC={rf_metrics[\"roc_auc\"]:.3f})', color='blue')\n",
    "axes[1, 0].plot(fpr_xgb, tpr_xgb, label=f'GradientBoosting (AUC={xgb_metrics[\"roc_auc\"]:.3f})', color='green')\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "axes[1, 0].set_xlabel('False Positive Rate')\n",
    "axes[1, 0].set_ylabel('True Positive Rate')\n",
    "axes[1, 0].set_title('ROC Curves Comparison')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Model Comparison Bar Chart\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1', 'ROC-AUC']\n",
    "rf_values = [rf_metrics['accuracy'], rf_metrics['precision'], rf_metrics['recall'], rf_metrics['f1'], rf_metrics['roc_auc']]\n",
    "xgb_values = [xgb_metrics['accuracy'], xgb_metrics['precision'], xgb_metrics['recall'], xgb_metrics['f1'], xgb_metrics['roc_auc']]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 1].bar(x - width/2, rf_values, width, label='RandomForest', color='#3498db')\n",
    "axes[1, 1].bar(x + width/2, xgb_values, width, label='GradientBoosting', color='#2ecc71')\n",
    "axes[1, 1].set_xlabel('Metric')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_title('Model Comparison')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(metrics_names)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa3cd9",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9854ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from best model\n",
    "importances = best_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_df['feature'], feature_importance_df['importance'], color='#3498db')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title(f'Feature Importance - {best_model_name}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top 10 most important features\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "for i, row in feature_importance_df.tail(10).iloc[::-1].iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe5179",
   "metadata": {},
   "source": [
    "## 10. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory\n",
    "MODELS_DIR = \"../models\"\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Save model and scaler\n",
    "model_path = os.path.join(MODELS_DIR, \"failure_predictor.joblib\")\n",
    "scaler_path = os.path.join(MODELS_DIR, \"scaler.joblib\")\n",
    "\n",
    "joblib.dump(best_model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Save feature list\n",
    "feature_list_path = os.path.join(MODELS_DIR, \"features.json\")\n",
    "with open(feature_list_path, 'w') as f:\n",
    "    json.dump(feature_columns, f, indent=2)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'n_samples': len(X),\n",
    "    'n_features': len(feature_columns),\n",
    "    'features': feature_columns,\n",
    "    'metrics': {\n",
    "        'accuracy': float(best_metrics['accuracy']),\n",
    "        'precision': float(best_metrics['precision']),\n",
    "        'recall': float(best_metrics['recall']),\n",
    "        'f1_score': float(best_metrics['f1']),\n",
    "        'roc_auc': float(best_metrics['roc_auc'])\n",
    "    },\n",
    "    'hyperparameters': grid_search_rf.best_params_ if best_model_name == \"RandomForest\" else grid_search_xgb.best_params_,\n",
    "    'version': '1.0.0'\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(MODELS_DIR, \"model_metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"âœ… Model artifacts saved:\")\n",
    "print(f\"   - Model: {model_path}\")\n",
    "print(f\"   - Scaler: {scaler_path}\")\n",
    "print(f\"   - Features: {feature_list_path}\")\n",
    "print(f\"   - Metadata: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f824da",
   "metadata": {},
   "source": [
    "## 11. Test Prediction API Response Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c01d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_failure(vehicle_data, model, scaler, feature_cols):\n",
    "    \"\"\"\n",
    "    Generate prediction in API response format.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {probability, failure_window_days, severity, component, explanation}\n",
    "    \"\"\"\n",
    "    # Prepare features (assuming vehicle_data is a dict)\n",
    "    features = np.array([[vehicle_data.get(col, 0) for col in feature_cols]])\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Get prediction\n",
    "    probability = model.predict_proba(features_scaled)[0][1]\n",
    "    \n",
    "    # Determine severity\n",
    "    if probability > 0.8:\n",
    "        severity = \"Critical\"\n",
    "        failure_window = max(1, int(7 * (1 - probability)))\n",
    "    elif probability > 0.6:\n",
    "        severity = \"High\"\n",
    "        failure_window = max(7, int(14 * (1 - probability)))\n",
    "    elif probability > 0.4:\n",
    "        severity = \"Medium\"\n",
    "        failure_window = max(14, int(30 * (1 - probability)))\n",
    "    elif probability > 0.2:\n",
    "        severity = \"Low\"\n",
    "        failure_window = max(30, int(60 * (1 - probability)))\n",
    "    else:\n",
    "        severity = \"Normal\"\n",
    "        failure_window = 90\n",
    "    \n",
    "    # Identify potential issues\n",
    "    issues = []\n",
    "    if vehicle_data.get('engine_temp', 90) > 105:\n",
    "        issues.append(\"Engine overheating\")\n",
    "    if vehicle_data.get('oil_pressure', 40) < 30:\n",
    "        issues.append(\"Low oil pressure\")\n",
    "    if vehicle_data.get('battery_voltage', 12) < 11.5:\n",
    "        issues.append(\"Battery degradation\")\n",
    "    if vehicle_data.get('brake_pad_wear_avg', 0.5) < 0.2:\n",
    "        issues.append(\"Brake pads need replacement\")\n",
    "    if vehicle_data.get('coolant_level', 1) < 0.6:\n",
    "        issues.append(\"Low coolant\")\n",
    "    \n",
    "    # Generate explanation\n",
    "    if issues:\n",
    "        explanation = f\"Detected issues: {', '.join(issues)}. \"\n",
    "    else:\n",
    "        explanation = \"No critical issues detected. \"\n",
    "    \n",
    "    if severity in [\"Critical\", \"High\"]:\n",
    "        explanation += \"Immediate service recommended.\"\n",
    "    elif severity == \"Medium\":\n",
    "        explanation += \"Schedule service within 1-2 weeks.\"\n",
    "    else:\n",
    "        explanation += \"Continue regular maintenance schedule.\"\n",
    "    \n",
    "    return {\n",
    "        \"vehicle_id\": vehicle_data.get('vehicle_id', 'UNKNOWN'),\n",
    "        \"failure_probability\": round(float(probability), 4),\n",
    "        \"failure_window_days\": failure_window,\n",
    "        \"severity\": severity,\n",
    "        \"predicted_failure_types\": issues if issues else [\"No immediate concerns\"],\n",
    "        \"explanation\": explanation,\n",
    "        \"confidence\": 0.85,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "# Test with sample vehicle data\n",
    "test_vehicle = {\n",
    "    'vehicle_id': 'VH007',\n",
    "    'engine_temp': 120.2,\n",
    "    'oil_pressure': 25.5,\n",
    "    'battery_voltage': 10.8,\n",
    "    'fuel_level': 12.5,\n",
    "    'tire_pressure_avg': 25.1,\n",
    "    'brake_pad_wear_avg': 0.11,\n",
    "    'odometer': 156780,\n",
    "    'speed': 42,\n",
    "    'rpm': 2100,\n",
    "    'coolant_level': 0.42,\n",
    "    'transmission_temp': 125.5,\n",
    "    'check_engine_light': 1,\n",
    "    'engine_health': 0.25,\n",
    "    'oil_health': 0.57,\n",
    "    'battery_health': 0.27,\n",
    "    'cooling_health': 0.42,\n",
    "    'trans_health': 0.09,\n",
    "    'overall_health': 0.32,\n",
    "    'mileage_normalized': 0.78,\n",
    "    'high_mileage': 1,\n",
    "    'risk_score': 4\n",
    "}\n",
    "\n",
    "prediction = predict_failure(test_vehicle, best_model, scaler, feature_columns)\n",
    "print(\"API Response Format Test:\")\n",
    "print(json.dumps(prediction, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b51124",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Performance\n",
    "- **Best Model**: Selected based on F1-score to balance precision and recall\n",
    "- **Key Features**: Engine temperature, oil pressure, overall health score, and risk indicators\n",
    "- **Use Case**: Real-time failure prediction for vehicle maintenance scheduling\n",
    "\n",
    "### Next Steps\n",
    "1. Deploy model via FastAPI endpoint (`/predict`)\n",
    "2. Set up model retraining pipeline\n",
    "3. Monitor model drift and performance\n",
    "4. Integrate with Master Agent for automated scheduling\n",
    "\n",
    "### Model Artifacts Location\n",
    "- `../models/failure_predictor.joblib` - Trained model\n",
    "- `../models/scaler.joblib` - Feature scaler\n",
    "- `../models/features.json` - Feature list\n",
    "- `../models/model_metadata.json` - Training metadata"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
